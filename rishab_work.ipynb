{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.losses import SmapeLoss\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import smape\n",
    "from darts.utils.utils import SeasonalityMode, TrendMode, ModelMode\n",
    "from darts.models import *\n",
    "\n",
    "from darts.datasets import TrafficDataset, AirPassengersDataset, AustralianTourismDataset\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "- We try multiple datasets to see which provides us with the best outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_occupancy_estimation = fetch_ucirepo(id=864) \n",
    "room_df = room_occupancy_estimation['data']['features']\n",
    "room_df = pd.concat([room_df, room_occupancy_estimation['data']['targets']], axis = 1)\n",
    "room_df['Capacity %'] = room_df['Room_Occupancy_Count']/max(room_df['Room_Occupancy_Count'])\n",
    "\n",
    "airpass_raw = AirPassengersDataset().load().pd_dataframe().reset_index()\n",
    "airpass_raw.columns.name = None\n",
    "\n",
    "airpass_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airpassenger Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "- Scale the data\n",
    "    - Make sure each data entry is $0\\leq x\\leq 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find local minimums and plot the month\n",
    "airpass_data = airpass_raw.copy()\n",
    "airpass_data['LMin'] = 0\n",
    "airpass_data['LMax'] = 0\n",
    "passengers = []\n",
    "\n",
    "for row, index in airpass_data.iterrows():\n",
    "    passengers.append(index['#Passengers'])\n",
    "    \n",
    "for i in range(len(passengers)):\n",
    "    if i > 0 and i < len(passengers)-1:\n",
    "        if passengers[i] < passengers[i-1] and passengers[i] < passengers[i+1]:\n",
    "            airpass_data.loc[i, \"LMin\"] = 1\n",
    "        if passengers[i] > passengers[i-1] and passengers[i] > passengers[i+1]:\n",
    "            airpass_data.loc[i, \"LMax\"] = 1\n",
    "\n",
    "## Keep out these values to prevent any errors\n",
    "to_conc = airpass_data[['Month', \"LMin\", \"LMax\"]]\n",
    "\n",
    "## Scale train and test\n",
    "scaler = MaxAbsScaler()\n",
    "airpass_scaled_data = pd.DataFrame(scaler.fit_transform(np.array(airpass_data.drop(columns = ['Month', \"LMin\", \"LMax\"])))).rename(columns = {0:\"# Passengers\"})\n",
    "\n",
    "## Add month to both\n",
    "airpass_scaled_data = pd.concat([to_conc, airpass_scaled_data], axis = 1)\n",
    "airpass_scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot scaled data\n",
    "- Looking at the data we see some trends\n",
    "    - Cyclical in nature\n",
    "    - Upward trend from 1950 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (12, 6))\n",
    "lmins = airpass_scaled_data[airpass_scaled_data['LMin'] == 1]\n",
    "lmaxs = airpass_scaled_data[airpass_scaled_data['LMax'] == 1]\n",
    "\n",
    "axes.plot(airpass_scaled_data['Month'], airpass_scaled_data['# Passengers'], label = '# Passengers')\n",
    "axes.set_xlabel(\"Month\")\n",
    "axes.set_ylabel(\"# Passengers\")\n",
    "axes.set_title(\"Scaled # Passengers over the months\")\n",
    "axes.scatter(lmins['Month'], lmins['# Passengers'], color='red', label = 'Local Min')\n",
    "axes.scatter(lmaxs['Month'], lmaxs['# Passengers'], color='blue', label = 'Local Max')\n",
    "axes.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model on the data\n",
    "- Invert the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format to TimeSeries\n",
    "past = 24\n",
    "future = 24\n",
    "airpass_ts = TimeSeries.from_dataframe(airpass_scaled_data, \"Month\", \"# Passengers\")\n",
    "airpass_ts = airpass_ts.astype('float32')\n",
    "\n",
    "model = NHiTSModel(input_chunk_length = past, output_chunk_length = future)\n",
    "model.fit(airpass_ts, verbose = 0)\n",
    "\n",
    "## Predict on self\n",
    "pred = model.predict(n = len(airpass_scaled_data['Month']), verbose = 0)\n",
    "\n",
    "## Plot predict v train\n",
    "results_df = pd.DataFrame(scaler.inverse_transform(pred.values())).rename(columns = {0:\"Predicted\"})\n",
    "results_df = pd.concat([airpass_scaled_data['Month'], results_df, \\\n",
    "                        pd.DataFrame(scaler.inverse_transform(airpass_ts.values()))], axis = 1)\\\n",
    "                        .rename(columns = {0:\"Actual\"})\n",
    "\n",
    "plt.plot(results_df['Month'], results_df['Predicted'], label = 'Predicted')\n",
    "plt.plot(results_df['Month'], results_df['Actual'], label = 'Actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mse = round(sum((results_df['Predicted'] - results_df['Actual'])**2)/len(results_df['Predicted']), 3)\n",
    "mape = round(sum(abs((results_df['Predicted'] - results_df['Actual'])))/len(results_df['Predicted']), 3)\n",
    "\n",
    "print(\"MSE =\", mse, \"\\nMAPE =\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air dataset\n",
    "- https://www.opendatanetwork.com/dataset/datahub.transportation.gov/xgub-n9bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_raw = pd.read_csv(\"carrier_passengers.csv\")\n",
    "carrier_df = carrier_raw[carrier_raw['Year'] == 2023].sort_values(by = 'data_dte').reset_index(drop = True)\n",
    "carrier_df = carrier_df.drop(columns=[\"data_dte\", \"usg_apt_id\", \"usg_wac\", \"fg_apt_id\", \"fg_wac\", \"airlineid\", \"type\", \"Scheduled\", \"Charter\"])\n",
    "\n",
    "carrier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric encoding\n",
    "- Tried one-hot and PCA, didn't work well\n",
    "    - Create the encoding for the flight and carrier, and use pca to determine which columns are most useful in determining the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['usg_apt', 'fg_apt', 'carrier']\n",
    "temp_df = carrier_df.copy()\n",
    "temp_df = temp_df[columns_to_encode]\n",
    "\n",
    "## Scale variables\n",
    "standard_scaler = StandardScaler()\n",
    "model_df = pd.DataFrame(standard_scaler.fit_transform(carrier_df.drop(columns = columns_to_encode)))\n",
    "model_df = pd.concat([model_df, temp_df], axis=1)\n",
    "\n",
    "## Construct encoders\n",
    "le_usg_apt = LabelEncoder()\n",
    "le_fg_apt = LabelEncoder()\n",
    "le_carrier = LabelEncoder()\n",
    "\n",
    "## Encode the data\n",
    "model_df['usg_apt_encoded'] = le_usg_apt.fit_transform(model_df['usg_apt'])\n",
    "model_df['fg_apt_encoded'] = le_fg_apt.fit_transform(model_df['fg_apt'])\n",
    "model_df['carrier_encoded'] = le_carrier.fit_transform(model_df['carrier'])\n",
    "model_df = model_df.drop(columns=['usg_apt', 'fg_apt', 'carrier']).rename(columns = {0: \"Year\", 1:\"Month\", 2:\"carriergroup\", 3:\"Total\"})\n",
    "\n",
    "# ## Conduct PCA\n",
    "# pca = PCA()\n",
    "# pca.fit(one_hot_scaled)\n",
    "# one_hot_pca = pca.transform(one_hot_scaled)\n",
    "# explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "# # ## Remove low variability\n",
    "# # one_hot.loc[-1] = list(explained_var)\n",
    "# # columns_to_drop = one_hot.columns[one_hot.iloc[-1] < (max(list(explained_var)) + min(list(explained_var)))/2]\n",
    "# # one_hot = one_hot.drop(columns=columns_to_drop)\n",
    "# # one_hot = one_hot.drop(-1)\n",
    "# # one_hot.head()\n",
    "\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_model_df = model_df.copy()\n",
    "\n",
    "target = air_model_df['Total']\n",
    "predictors = air_model_df.drop(columns=['Total', \"Year\"])\n",
    "\n",
    "## Format to TimeSeries\n",
    "past = 24\n",
    "future = 24\n",
    "predictors_ts = TimeSeries.from_dataframe(predictors)\n",
    "predictors_ts = predictors_ts.astype('float32')\n",
    "\n",
    "model = NHiTSModel(input_chunk_length = past, output_chunk_length = 5)\n",
    "model.fit(predictors_ts, epochs=100)\n",
    "\n",
    "## Predict on self\n",
    "pred = model.predict(n = len(air_model_df['Month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot predict v train\n",
    "# results_df = pd.DataFrame(standard_scaler.inverse_transform(pred.values()))\n",
    "# results_df = pd.concat([carrier_df['Month'], results_df, \\\n",
    "#                         target], axis = 1)\n",
    "# results_df = results_df[['Month', 'Predicted', 'Total']]\n",
    "# results_df = results_df.groupby(by = 'Month').sum().reset_index()\n",
    "\n",
    "# plt.plot(results_df['Month'], results_df['Predicted'], label = 'Predicted')\n",
    "# plt.plot(results_df['Month'], results_df['Actual'], label = 'Actual')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# mse = round(sum((results_df['Predicted'] - results_df['Actual'])**2)/len(results_df['Predicted']), 3)\n",
    "# mape = round(sum(abs((results_df['Predicted'] - results_df['Actual'])))/len(results_df['Predicted']), 3)\n",
    "\n",
    "# print(\"MSE =\", mse, \"\\nMAPE =\", mape)\n",
    "pred.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
